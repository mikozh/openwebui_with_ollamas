# openwebui_with_ollamas
Simple docker compose to setup openwebui using two ollama servers: one for embeddings another for LLM
